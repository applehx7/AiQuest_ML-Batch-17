{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113f2c8b-4845-43cd-ae39-f726f8f66900",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff9a8b9-c6dd-40b0-8a07-d637568160ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#used models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cc4fc4-2f24-479d-ba6b-e8dce0c25bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"amazon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7920415c-55d2-491c-9227-389f4ef0515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  This is a one of the best apps acording to a b...         1\n",
       "1  This is a pretty good version of the game for ...         1\n",
       "2  this is a really cool game. there are a bunch ...         1\n",
       "3  This is a silly game and can be frustrating, b...         1\n",
       "4  This is a terrific game on any pad. Hrs of fun...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8620807d-993d-409f-b063-e52a43d1140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.761650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.426085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Positive\n",
       "count  20000.000000\n",
       "mean       0.761650\n",
       "std        0.426085\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b13f58-ffc2-48b1-b868-2f4bb06cb9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   reviewText  20000 non-null  object\n",
      " 1   Positive    20000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047dabf-9485-4381-b284-bdb8ab138902",
   "metadata": {},
   "source": [
    "__Description of columns__\n",
    "\n",
    "    1. 'reviewText': textual content of the review\n",
    "    2. 'Positive': binary label (1 for positive, 0 for negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b5380-3e2d-4492-8834-ec18c26ff2bf",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d0cec8-ce41-44b3-aa66-6feff7b2f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca16f38-725c-4345-962e-98054ae6e31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.835"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Imbalanced Dataset\n",
    "a = data['Positive'].value_counts()[0]\n",
    "b= data['Positive'].value_counts().sum()\n",
    "\n",
    "(a/b) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9ea220-2caf-42cc-81f3-ca67f1e6b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation\n",
    "\n",
    "def remove_punc(text):\n",
    "    final_text = []\n",
    "    for i in text:\n",
    "        if i not in punctuations:\n",
    "            final_text.append(i)\n",
    "    final_text = ''.join(final_text)\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50fe4be0-334a-4a22-8a4c-6b9efb64a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "def remove_st(text):\n",
    "    text = text.lower()\n",
    "    final_text = [word for word in text.split() if word not in stopword]\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19e70aa0-5bef-4f67-b92f-2412952be066",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText'] = data['reviewText'].apply(remove_punc)\n",
    "data['reviewText'] = data['reviewText'].apply(remove_st)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f10b0-4b9d-41a7-b3e3-24b4aaaab372",
   "metadata": {},
   "source": [
    "#### Lemmatize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "041e5dbd-1089-4873-892f-e72bdd077d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemm_text(text_list):\n",
    "    text = [lemmatizer.lemmatize(word) for word in text_list]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a180a84-9524-45c5-9035-f7bfcf95be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText'] = data['reviewText'].apply(lemm_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05ba63-6b82-4244-9175-304484a248ac",
   "metadata": {},
   "source": [
    "#### Vectorize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83198371-a46f-44cc-8b69-e7d66007204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "x = vectorizer.fit_transform(data['reviewText'])\n",
    "y = data['Positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11191e31-2594-4116-a833-c124f18dc493",
   "metadata": {},
   "source": [
    "#### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a88f864-c83c-4441-9d4a-71d556c24989",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(x, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cca1547-d1af-4a57-8ac5-0fac6daa8959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14000, 22084)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7403e1b-d4dd-4dda-9ede-865380a1de44",
   "metadata": {},
   "source": [
    "### Model Selection and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a1a5aa-1da8-44d2-8b8e-ce0769ee287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    SVC()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c1a4fa4-b76e-495d-ad29-1644676fd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_md(model, X, Y, testX):\n",
    "    model.fit(X, Y)\n",
    "    predicted = model.predict(testX)\n",
    "    model_name = type(model).__name__\n",
    "    return model_name, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f60e6b9-02c0-454a-a218-1129807b4669",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb63e9fa-3447-40c9-82c7-bc774accc8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    name, pred = train_md(model, X_Train, Y_Train, X_Test)\n",
    "    model_info[name] = {'actual_Y': Y_Test, 'predicted_Y': pred}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a31a3f-201b-452c-bf0c-84edcf3d5562",
   "metadata": {},
   "source": [
    "### Formal Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b3d8334-730a-47f8-86eb-59040671edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(x, y):\n",
    "    sc = {\n",
    "            'accuracy' : accuracy_score(x, y),\n",
    "            'f1' : f1_score(x, y),\n",
    "            'recall' : recall_score(x, y),\n",
    "            'precision' : precision_score(x, y),\n",
    "            'cm' : confusion_matrix(x, y),\n",
    "    }\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8590d6a0-8797-44c1-817d-2577c7b218fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = {}\n",
    "\n",
    "for model_name in model_info:\n",
    "    sc = get_score(model_info[model_name]['actual_Y'], model_info[model_name]['predicted_Y'])\n",
    "    score[model_name] = sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdc59d7e-dd31-414a-87f9-a676b0fae9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------********-----------\n",
      "LogisticRegression\n",
      "accuracy : 0.8848333333333334\n",
      "f1 : 0.9280732799000729\n",
      "recall : 0.9714534757027675\n",
      "precision : 0.8884017536867278\n",
      "cm : [[ 851  560]\n",
      " [ 131 4458]]\n",
      "-----------********-----------\n",
      "RandomForestClassifier\n",
      "accuracy : 0.8625\n",
      "f1 : 0.9156355455568054\n",
      "recall : 0.9755938112878623\n",
      "precision : 0.8626204238921001\n",
      "cm : [[ 698  713]\n",
      " [ 112 4477]]\n",
      "-----------********-----------\n",
      "MultinomialNB\n",
      "accuracy : 0.7885\n",
      "f1 : 0.8782032824647279\n",
      "recall : 0.9969492264109828\n",
      "precision : 0.7847341337907375\n",
      "cm : [[ 156 1255]\n",
      " [  14 4575]]\n",
      "-----------********-----------\n",
      "BernoulliNB\n",
      "accuracy : 0.865\n",
      "f1 : 0.915625\n",
      "recall : 0.9577249945521901\n",
      "precision : 0.8770704450209539\n",
      "cm : [[ 795  616]\n",
      " [ 194 4395]]\n",
      "-----------********-----------\n",
      "SVC\n",
      "accuracy : 0.8888333333333334\n",
      "f1 : 0.9303248720359345\n",
      "recall : 0.97036391370669\n",
      "precision : 0.8934590690208668\n",
      "cm : [[ 880  531]\n",
      " [ 136 4453]]\n"
     ]
    }
   ],
   "source": [
    "for name in score:\n",
    "    print(\"-----------********-----------\")\n",
    "    print(name)\n",
    "    for i in score[name]:\n",
    "        print(i, \":\", score[name][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757df6b3-da6f-49ce-9c05-fe3f9e4bb473",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dff93fe5-be9d-499d-94e3-f2bcdc000d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_model = {\n",
    "    'lr': {'model': LogisticRegression(),\n",
    "            'params':{\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'C': [1.0, 2.0],\n",
    "                'solver': ['liblinear'],\n",
    "                'max_iter': [20, 50, 100],\n",
    "    }\n",
    "},\n",
    "    'rf': {'model': RandomForestClassifier(),\n",
    "            'params':{\n",
    "                'n_estimators': [20, 50, 100],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'min_samples_leaf': [1, 2],\n",
    "                'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "},\n",
    "    'mb': {'model': MultinomialNB(),\n",
    "            'params':{\n",
    "                'force_alpha': [True, False],\n",
    "                'fit_prior': [True, False]\n",
    "            }\n",
    "},\n",
    "    'bb': {'model': BernoulliNB(),\n",
    "            'params':{\n",
    "                'alpha': [1.0, 2.0],\n",
    "                'force_alpha': [True, False]\n",
    "            }\n",
    "},\n",
    "    'svc': {'model': SVC(),\n",
    "            'params':{\n",
    "                'C': [1.0, 2.0],\n",
    "                'kernel': ['linear', 'rbf'],\n",
    "            }\n",
    "} \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b2844f0-6ef8-47e3-b95b-621e2539e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f1374df-3f3f-4fb0-b98e-2e8a41fd3564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/applehx7/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/applehx7/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/applehx7/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for mName in HP_model:\n",
    "    model = HP_model[mName]['model']\n",
    "    params = HP_model[mName]['params']\n",
    "    clf = RandomizedSearchCV(model, param_distributions=params, random_state=0)\n",
    "    clf = clf.fit(X_Train, Y_Train)\n",
    "    HP_res[mName] = {'model': model, 'score': clf.best_score_, 'Bparams': clf.best_estimator_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ba274d6-56df-4f41-be69-3d5366560534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': {'model': LogisticRegression(),\n",
       "  'score': 0.8885714285714286,\n",
       "  'Bparams': LogisticRegression(C=2.0, solver='liblinear')},\n",
       " 'rf': {'model': RandomForestClassifier(),\n",
       "  'score': 0.8654999999999999,\n",
       "  'Bparams': RandomForestClassifier(criterion='entropy')},\n",
       " 'mb': {'model': MultinomialNB(),\n",
       "  'score': 0.8447857142857144,\n",
       "  'Bparams': MultinomialNB(fit_prior=False, force_alpha=True)},\n",
       " 'bb': {'model': BernoulliNB(),\n",
       "  'score': 0.8521428571428571,\n",
       "  'Bparams': BernoulliNB(force_alpha=True)},\n",
       " 'svc': {'model': SVC(), 'score': 0.8951428571428572, 'Bparams': SVC(C=2.0)}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HP_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a695c5-4722-4f49-809f-0a9b1966c7fd",
   "metadata": {},
   "source": [
    "### Explanation of Chosen Hyperparameters:\n",
    "1. __Logistic Regression (lr):__\n",
    "\n",
    "    - penalty: Specifies the norm used in the penalization. l1 and l2 are commonly used penalties for regularization.\n",
    "    - C: Regularization parameter. It controls the trade-off between fitting the training data well and keeping the model simple.\n",
    "    - solver: Algorithm used for optimization. 'liblinear' is suitable for small-to-medium-sized datasets.\n",
    "    - max_iter: Maximum number of iterations taken for the solvers to converge.\n",
    "\n",
    "\n",
    "2. __Random Forest (rf):__\n",
    "    - n_estimators: The number of trees in the forest. Different values like [20, 50, 100] are tested to find the optimal number of trees.\n",
    "    - criterion: Function to measure the quality of a split. 'gini' and 'entropy' are criteria for impurity.\n",
    "    - min_samples_leaf: Minimum number of samples required to be at a leaf node.\n",
    "    - max_features: The number of features to consider when looking for the best split.\n",
    "\n",
    "\n",
    "3. __Multinomial Naive Bayes (mb):__\n",
    "   \n",
    "    - force_alpha: This parameter is not a standard hyperparameter for MultinomialNB in scikit-learn. It might be specific to your implementation or a custom hyperparameter.\n",
    "    - fit_prior: Boolean parameter specifying whether to learn class prior probabilities or not.\n",
    "\n",
    "\n",
    "5. __Bernoulli Naive Bayes (bb):__\n",
    "\n",
    "    - alpha: This parameter is used for Laplace smoothing. Different values like [1.0, 2.0] are tested.\n",
    "    - force_alpha: Similar to the force_alpha parameter in MultinomialNB, this may be a custom hyperparameter.\n",
    "\n",
    "\n",
    "6. __Support Vector Classifier (svc):__\n",
    "\n",
    "    - C: Penalty parameter for the error term. Different values like [1.0, 2.0] are tested.\n",
    "    - kernel: Type of kernel used in the algorithm. 'linear' and 'rbf' are commonly used kernels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504b0bbd-2900-4cd5-b6dd-353a68bb68c5",
   "metadata": {},
   "source": [
    "### Reasoning behind the Chosen Hyperparameters:\n",
    "- __Exploration of Different Aspects:__ The chosen hyperparameters cover various aspects of each model, such as regularization, model complexity, kernel choice, and criterion for split.\n",
    "\n",
    "- __Range Selection:__ The ranges provided seem to be a good starting point for exploration. For example, testing different values of C, n_estimators, or different penalties in Logistic Regression and Naive Bayes.\n",
    "\n",
    "- __Common Defaults:__ Some hyperparameters like C, kernel, penalty, and n_estimators are widely used defaults and essential for model behavior control.\n",
    "\n",
    "- __Model-Specific Parameters:__ There are instances of potentially model-specific parameters like force_alpha in Naive Bayes, which might be used for custom implementations or specific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c51a6-f896-40b7-87e7-caad6631ad10",
   "metadata": {},
   "source": [
    "### Comaparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "132c15e8-16f7-42ce-8953-3c0bc32e98ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "{'Accuracy': 0.8918333333333334, 'Precision': 0.9023692810457516, 'Recall': 0.9627369797341468, 'F1 Score': 0.9315761729045862, 'Confusion Matrix': array([[ 933,  478],\n",
      "       [ 171, 4418]])}\n",
      "Model: RandomForestClassifier\n",
      "{'Accuracy': 0.8651666666666666, 'Precision': 0.8664210934470725, 'Recall': 0.9738505120941382, 'F1 Score': 0.9170001025956706, 'Confusion Matrix': array([[ 722,  689],\n",
      "       [ 120, 4469]])}\n",
      "Model: MultinomialNB\n",
      "{'Accuracy': 0.855, 'Precision': 0.8609978644923316, 'Recall': 0.9664414905208106, 'F1 Score': 0.9106776180698153, 'Confusion Matrix': array([[ 695,  716],\n",
      "       [ 154, 4435]])}\n",
      "Model: BernoulliNB\n",
      "{'Accuracy': 0.865, 'Precision': 0.8770704450209539, 'Recall': 0.9577249945521901, 'F1 Score': 0.915625, 'Confusion Matrix': array([[ 795,  616],\n",
      "       [ 194, 4395]])}\n",
      "Model: SVC\n",
      "{'Accuracy': 0.893, 'Precision': 0.90515294600698, 'Recall': 0.9607757681412072, 'F1 Score': 0.9321353065539112, 'Confusion Matrix': array([[ 949,  462],\n",
      "       [ 180, 4409]])}\n"
     ]
    }
   ],
   "source": [
    "results = {} \n",
    "\n",
    "for mName in HP_res:\n",
    "    clf = HP_res[mName]['Bparams']\n",
    "    model = HP_res[mName]['model']\n",
    "    y_pred = clf.predict(X_Test)\n",
    "    accuracy = accuracy_score(Y_Test, y_pred)\n",
    "    precision = precision_score(Y_Test, y_pred)\n",
    "    recall = recall_score(Y_Test, y_pred)\n",
    "    f1 = f1_score(Y_Test, y_pred)\n",
    "    cm = confusion_matrix(Y_Test, y_pred)\n",
    "    \n",
    "    results[type(model).__name__] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1, 'Confusion Matrix': cm}\n",
    "\n",
    "\n",
    "# Print evaluation metrics for each model\n",
    "for mName, metrics in results.items():\n",
    "    print(f\"Model: {mName}\")\n",
    "    print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323426a9-043c-4053-aa3e-c55440b58717",
   "metadata": {},
   "source": [
    "### Identify the strengths and weaknesses of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3457f6e-5d7f-4f11-b1c6-f7f906ba406f",
   "metadata": {},
   "source": [
    "1. __Logistic Regression:__\n",
    "\n",
    "    1. Strengths:\n",
    "        - Provides probabilities for predictions.\n",
    "        - Works well with a large number of features.\n",
    "    2. Weaknesses:\n",
    "        - Prone to underperform if features are not linearly separable.\n",
    "        - May not capture complex relationships between features.\n",
    "2. __Random Forest Classifier:__\n",
    "\n",
    "    1. Strengths:\n",
    "        - Handles non-linearity and interactions well.\n",
    "        - Works with both numerical and categorical data.\n",
    "        - Less prone to overfitting compared to decision trees.\n",
    "    2. Weaknesses:\n",
    "        - Can be computationally expensive for large datasets.\n",
    "        - Interpretability might be challenging with a large number of trees.\n",
    "3. __Multinomial Naive Bayes:__\n",
    "\n",
    "    1. Strengths:\n",
    "        - Efficient and simple algorithm.\n",
    "        - Handles high-dimensional data well, often used in text classification.\n",
    "    2. Weaknesses:\n",
    "        - Assumes independence between features (features are conditionally independent given the class), which might not hold true in real-world scenarios.\n",
    "        - Doesn't handle negative values well (as it's specifically designed for features representing word counts).\n",
    "4. __Bernoulli Naive Bayes:__\n",
    "\n",
    "    1. Strengths:\n",
    "        - Suitable for binary/boolean features.\n",
    "        - Performs well with a small amount of training data.\n",
    "    2. Weaknesses:\n",
    "        - Similar to Multinomial Naive Bayes, assumes feature independence.\n",
    "        - Sensitive to feature distributions; doesn't perform well with continuous or non-binary data.\n",
    "5. __Support Vector Classifier (SVC):__\n",
    "\n",
    "    1. S- trengths:\n",
    "        Effective in high-dimensional spaces.\n",
    "        - Versatile due to different kernel options for non-linear classification.\n",
    "    2. Weaknesses:\n",
    "        - Computationally expensive with large datasets.\n",
    "        - Sensitivity to the choice of kernel and regularization parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c29f401-543c-45c2-b1a5-9dc6e04309c1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The analysis aimed to assess various machine learning models for sentiment analysis using Amazon product reviews. Five models, namely Logistic Regression, Random Forest, Multinomial Naive Bayes, Bernoulli Naive Bayes, and Support Vector Classifier (SVC), were evaluated based on their performance metrics on a test dataset.\n",
    "\n",
    "The findings revealed diverse performances among the models, each demonstrating distinct strengths and weaknesses. Notably, the Support Vector Classifier (SVC) exhibited slightly superior accuracy and F1 score compared to the other models. However, each model showcased specific characteristics:\n",
    "\n",
    "- __Logistic Regression__ performed consistently well and provided probabilities for predictions, but its performance heavily relied on linear separability of features.\n",
    "\n",
    "- __Random Forest Classifier__ demonstrated robustness against overfitting, handling non-linearity effectively. However, its interpretability and computational cost might be challenges in some scenarios.\n",
    "\n",
    "- __Naive Bayes__ models—Multinomial and Bernoulli—proved efficient and straightforward but relied on the independence assumption among features, which might not hold in all situations.\n",
    "\n",
    "- __SVC__ showcased strong predictive capabilities in high-dimensional spaces, but its computational intensity and sensitivity to kernel selection were noteworthy limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2dec6d-926c-4dc5-aa4a-2e7db5520103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
